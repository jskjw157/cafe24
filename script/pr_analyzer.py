#!/usr/bin/env python3
"""
PR Analyzer
GitHub PRì˜ ë³€ê²½ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ íŒŒì¼ë³„ ì˜í–¥ë„, ë¦¬ìŠ¤í¬ ìˆ˜ì¤€, ë¦¬ë·° ìš°ì„ ìˆœìœ„ë¥¼ JSONìœ¼ë¡œ ì¶œë ¥
"""

import json
import subprocess
import re
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict


@dataclass
class FileChange:
    """íŒŒì¼ ë³€ê²½ ì •ë³´"""
    path: str
    additions: int
    deletions: int
    status: str  # added, modified, deleted, renamed
    risk_level: str  # critical, high, medium, low
    risk_reasons: List[str]
    review_priority: int  # 1 (highest) ~ 5 (lowest)


class PrAnalyzer:
    """GitHub PR ë¶„ì„ê¸°"""

    # ê³ ìœ„í—˜ íŒŒì¼ íŒ¨í„´
    CRITICAL_PATTERNS = [
        (r"\.env", "í™˜ê²½ ë³€ìˆ˜ íŒŒì¼"),
        (r"secrets?\.ya?ml", "ì‹œí¬ë¦¿ ì„¤ì •"),
        (r"credentials", "ì¸ì¦ ì •ë³´"),
        (r"auth", "ì¸ì¦ ê´€ë ¨"),
        (r"security", "ë³´ì•ˆ ê´€ë ¨"),
        (r"password|passwd", "ë¹„ë°€ë²ˆí˜¸ ê´€ë ¨"),
    ]

    HIGH_RISK_PATTERNS = [
        (r"config.*\.(ya?ml|json|toml)", "ì„¤ì • íŒŒì¼"),
        (r"docker", "Docker ì„¤ì •"),
        (r"k8s|kubernetes", "Kubernetes ì„¤ì •"),
        (r"ci|cd|pipeline", "CI/CD íŒŒì´í”„ë¼ì¸"),
        (r"build\.gradle|pom\.xml|package\.json", "ë¹Œë“œ ì„¤ì •"),
        (r"migrations?/", "DB ë§ˆì´ê·¸ë ˆì´ì…˜"),
        (r"schema", "ìŠ¤í‚¤ë§ˆ ë³€ê²½"),
    ]

    MEDIUM_RISK_PATTERNS = [
        (r"(service|controller|handler)\.(kt|java|py|ts|js)$", "í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§"),
        (r"(repository|dao)\.(kt|java|py|ts|js)$", "ë°ì´í„° ì ‘ê·¼ ê³„ì¸µ"),
        (r"api/", "API ì—”ë“œí¬ì¸íŠ¸"),
    ]

    def __init__(self, pr_number: Optional[int] = None, base_branch: str = "main"):
        self.pr_number = pr_number
        self.base_branch = base_branch
        self.files: List[FileChange] = []

    def analyze(self) -> Dict[str, Any]:
        """PR ë¶„ì„ ì‹¤í–‰"""
        print(f"ğŸ” Analyzing PR{'#' + str(self.pr_number) if self.pr_number else ''}...\n")

        if self.pr_number:
            self._analyze_pr()
        else:
            self._analyze_local_diff()

        self._calculate_priorities()

        return self._generate_report()

    def _analyze_pr(self) -> None:
        """GitHub PR ë¶„ì„"""
        try:
            # PR íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            result = subprocess.run(
                ["gh", "pr", "view", str(self.pr_number), "--json", "files,additions,deletions"],
                capture_output=True,
                text=True,
                timeout=30
            )

            if result.returncode != 0:
                print(f"âš ï¸  Failed to fetch PR: {result.stderr}")
                return

            data = json.loads(result.stdout)

            for file in data.get("files", []):
                self._analyze_file(
                    path=file.get("path", ""),
                    additions=file.get("additions", 0),
                    deletions=file.get("deletions", 0),
                    status="modified"
                )

            print(f"âœ… Analyzed {len(self.files)} files from PR #{self.pr_number}")

        except FileNotFoundError:
            print("âš ï¸  gh CLI not found. Install: https://cli.github.com")
        except subprocess.TimeoutExpired:
            print("âš ï¸  gh command timeout")
        except Exception as e:
            print(f"âš ï¸  Error analyzing PR: {e}")

    def _analyze_local_diff(self) -> None:
        """ë¡œì»¬ git diff ë¶„ì„"""
        try:
            # git diff --statìœ¼ë¡œ ë³€ê²½ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            result = subprocess.run(
                ["git", "diff", "--numstat", f"{self.base_branch}...HEAD"],
                capture_output=True,
                text=True,
                timeout=30
            )

            if result.returncode != 0:
                # base branchì™€ ë¹„êµ ì‹¤íŒ¨ ì‹œ HEADì™€ ë¹„êµ
                result = subprocess.run(
                    ["git", "diff", "--numstat", "HEAD"],
                    capture_output=True,
                    text=True,
                    timeout=30
                )

            for line in result.stdout.strip().split("\n"):
                if not line:
                    continue

                parts = line.split("\t")
                if len(parts) >= 3:
                    additions = int(parts[0]) if parts[0] != "-" else 0
                    deletions = int(parts[1]) if parts[1] != "-" else 0
                    path = parts[2]

                    self._analyze_file(
                        path=path,
                        additions=additions,
                        deletions=deletions,
                        status="modified"
                    )

            print(f"âœ… Analyzed {len(self.files)} changed files")

        except Exception as e:
            print(f"âš ï¸  Error analyzing local diff: {e}")

    def _analyze_file(self, path: str, additions: int, deletions: int, status: str) -> None:
        """ê°œë³„ íŒŒì¼ ë¶„ì„"""
        risk_level, risk_reasons = self._assess_risk(path, additions, deletions)

        self.files.append(FileChange(
            path=path,
            additions=additions,
            deletions=deletions,
            status=status,
            risk_level=risk_level,
            risk_reasons=risk_reasons,
            review_priority=0  # ë‚˜ì¤‘ì— ê³„ì‚°
        ))

    def _assess_risk(self, path: str, additions: int, deletions: int) -> tuple:
        """íŒŒì¼ ë¦¬ìŠ¤í¬ í‰ê°€"""
        reasons = []
        path_lower = path.lower()

        # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë¦¬ìŠ¤í¬ í‰ê°€
        for pattern, reason in self.CRITICAL_PATTERNS:
            if re.search(pattern, path_lower):
                reasons.append(f"ğŸ”´ {reason}")
                return "critical", reasons

        for pattern, reason in self.HIGH_RISK_PATTERNS:
            if re.search(pattern, path_lower):
                reasons.append(f"ğŸŸ  {reason}")

        for pattern, reason in self.MEDIUM_RISK_PATTERNS:
            if re.search(pattern, path_lower):
                reasons.append(f"ğŸŸ¡ {reason}")

        # ë³€ê²½ëŸ‰ ê¸°ë°˜ ë¦¬ìŠ¤í¬
        total_changes = additions + deletions
        if total_changes > 500:
            reasons.append(f"ğŸŸ  ëŒ€ê·œëª¨ ë³€ê²½ ({total_changes}ì¤„)")
        elif total_changes > 200:
            reasons.append(f"ğŸŸ¡ ì¤‘ê°„ ê·œëª¨ ë³€ê²½ ({total_changes}ì¤„)")

        # ì‚­ì œ ë¹„ìœ¨ì´ ë†’ìœ¼ë©´ ì£¼ì˜
        if deletions > 0 and deletions > additions * 2:
            reasons.append("ğŸŸ¡ ì‚­ì œ ìœ„ì£¼ ë³€ê²½")

        # ë¦¬ìŠ¤í¬ ë ˆë²¨ ê²°ì •
        if any("ğŸ”´" in r for r in reasons):
            return "critical", reasons
        elif any("ğŸŸ " in r for r in reasons):
            return "high", reasons
        elif any("ğŸŸ¡" in r for r in reasons):
            return "medium", reasons
        else:
            return "low", ["ì¼ë°˜ ë³€ê²½"]

    def _calculate_priorities(self) -> None:
        """ë¦¬ë·° ìš°ì„ ìˆœìœ„ ê³„ì‚°"""
        risk_order = {"critical": 0, "high": 1, "medium": 2, "low": 3}

        # ë¦¬ìŠ¤í¬ì™€ ë³€ê²½ëŸ‰ìœ¼ë¡œ ì •ë ¬
        sorted_files = sorted(
            self.files,
            key=lambda f: (risk_order.get(f.risk_level, 4), -(f.additions + f.deletions))
        )

        # ìš°ì„ ìˆœìœ„ í• ë‹¹
        for i, file in enumerate(sorted_files):
            if file.risk_level == "critical":
                file.review_priority = 1
            elif file.risk_level == "high":
                file.review_priority = 2
            elif file.risk_level == "medium":
                file.review_priority = 3
            else:
                file.review_priority = 4

        self.files = sorted_files

    def _generate_report(self) -> Dict[str, Any]:
        """ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        summary = {
            "total_files": len(self.files),
            "critical": sum(1 for f in self.files if f.risk_level == "critical"),
            "high": sum(1 for f in self.files if f.risk_level == "high"),
            "medium": sum(1 for f in self.files if f.risk_level == "medium"),
            "low": sum(1 for f in self.files if f.risk_level == "low"),
            "total_additions": sum(f.additions for f in self.files),
            "total_deletions": sum(f.deletions for f in self.files),
        }

        return {
            "pr_number": self.pr_number,
            "base_branch": self.base_branch,
            "summary": summary,
            "files": [asdict(f) for f in self.files],
            "review_order": [f.path for f in self.files[:10]],  # ìƒìœ„ 10ê°œ
        }


def main():
    """CLI ì‹¤í–‰"""
    import argparse

    parser = argparse.ArgumentParser(description="PR Analyzer")
    parser.add_argument("--pr", type=int, help="GitHub PR number")
    parser.add_argument("--base", default="main", help="Base branch for comparison")
    parser.add_argument("--output", "-o", default=".claude/pr-analysis.json", help="Output file")

    args = parser.parse_args()

    analyzer = PrAnalyzer(pr_number=args.pr, base_branch=args.base)
    report = analyzer.analyze()

    # ê²°ê³¼ ì €ì¥
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ“„ Report saved to: {output_path}")
    print(f"\nğŸ“Š Summary:")
    print(f"  - Total files: {report['summary']['total_files']}")
    print(f"  - Critical: {report['summary']['critical']}")
    print(f"  - High: {report['summary']['high']}")
    print(f"  - Medium: {report['summary']['medium']}")
    print(f"  - Low: {report['summary']['low']}")
    print(f"  - Changes: +{report['summary']['total_additions']} / -{report['summary']['total_deletions']}")

    if report['review_order']:
        print(f"\nğŸ¯ Review Order (Top 10):")
        for i, path in enumerate(report['review_order'], 1):
            print(f"  {i}. {path}")


if __name__ == "__main__":
    main()
